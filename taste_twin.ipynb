{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPB7R8Fnosnh4IObtarg7iq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekang100/taste-twin/blob/main/taste_twin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xCuJnFqvIam"
      },
      "outputs": [],
      "source": [
        "#pip install pandas scikit-learn sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Playing with Mock Data"
      ],
      "metadata": {
        "id": "d90No8_YIna0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "VgtKyObVv54_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## mock data\n",
        "\n",
        "# restaurants\n",
        "restaurant_metadata = {\n",
        "    \"leo\": {\n",
        "        \"cuisines\": [\"Italian\"],\n",
        "        \"tags\": [\"date night\", \"natural wine\", \"cozy\"],\n",
        "        \"price\": \"$$$\",\n",
        "        \"location\": \"SoHo\"\n",
        "    },\n",
        "    \"ugly baby\": {\n",
        "        \"cuisines\": [\"Thai\"],\n",
        "        \"tags\": [\"spicy\", \"authentic\", \"no reservations\"],\n",
        "        \"price\": \"$$\",\n",
        "        \"location\": \"Carroll Gardens\"\n",
        "    },\n",
        "    \"kiki\": {\n",
        "        \"cuisines\": [\"Greek\"],\n",
        "        \"tags\": [\"casual\", \"cheap eats\", \"group-friendly\"],\n",
        "        \"price\": \"$\",\n",
        "        \"location\": \"LES\"\n",
        "    },\n",
        "    \"roscioli\": {\n",
        "        \"cuisines\": [\"Italian\"],\n",
        "        \"tags\": [\"pasta\", \"tasting menu\", \"famous\"],\n",
        "        \"price\": \"$$$$\",\n",
        "        \"location\": \"Rome\"  # could be normalized to \"International\"\n",
        "    },\n",
        "    \"jeju noodle bar\": {\n",
        "        \"cuisines\": [\"Korean\"],\n",
        "        \"tags\": [\"spicy\", \"trendy\", \"noodle-forward\"],\n",
        "        \"price\": \"$$$\",\n",
        "        \"location\": \"West Village\"\n",
        "    },\n",
        "    \"cervoâ€™s\": {\n",
        "        \"cuisines\": [\"Spanish\", \"Seafood\"],\n",
        "        \"tags\": [\"natural wine\", \"cozy\", \"date night\"],\n",
        "        \"price\": \"$$$\",\n",
        "        \"location\": \"Chinatown\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# users\n",
        "userA = {\n",
        "    \"username\": \"jaysen\",\n",
        "    \"been\": {\n",
        "        \"leo\": 1.0,\n",
        "        \"ugly baby\": 2.0,\n",
        "        \"kiki\": 4.5\n",
        "    },\n",
        "    \"want_to_try\": [\"roscioli\", \"jeju noodle bar\"],\n",
        "    \"reviews\": [\n",
        "        \"vibes and wine were immaculate at leo\",\n",
        "        \"flavors at ugly baby were wild â€” spicy and rich\",\n",
        "        \"kiki is super casual, went with friends after work\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "userB = {\n",
        "    \"username\": \"alex\",\n",
        "    \"been\": {\n",
        "        \"ugly baby\": 1.2,\n",
        "        \"jeju noodle bar\": 2.5,\n",
        "        \"cervoâ€™s\": 3.7\n",
        "    },\n",
        "    \"want_to_try\": [\"leo\", \"roscioli\"],\n",
        "    \"reviews\": [\n",
        "        \"jeju was clean, spicy, modern â€” loved it\",\n",
        "        \"cervoâ€™s was cozy and great with natural wine\",\n",
        "        \"ugly baby is always my go-to for heat\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "SV796r5mv6gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build \"taste\" vectors\n",
        "\n",
        "from collections import defaultdict\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def normalize_dict(d):\n",
        "    total = sum(d.values())\n",
        "    return {k: v / total for k, v in d.items()} if total > 0 else d\n",
        "\n",
        "def build_vector(user, metadata, field, want_weight=0.3):\n",
        "    vec = defaultdict(float)\n",
        "\n",
        "    # Strong signal: Been list\n",
        "    for r, rank in user[\"been\"].items():\n",
        "        weight = 1 / rank\n",
        "        values = metadata[r][field]\n",
        "        if isinstance(values, list):\n",
        "            for val in values:\n",
        "                vec[val] += weight\n",
        "        else:\n",
        "            vec[values] += weight\n",
        "\n",
        "    # Weak signal: Want to try list\n",
        "    for r in user.get(\"want_to_try\", []):\n",
        "        if r in metadata:\n",
        "            values = metadata[r][field]\n",
        "            if isinstance(values, list):\n",
        "                for val in values:\n",
        "                    vec[val] += want_weight\n",
        "            else:\n",
        "                vec[values] += want_weight\n",
        "\n",
        "    return normalize_dict(vec)\n",
        "\n",
        "\n",
        "def build_price_vector(user, metadata):\n",
        "    return build_vector(user, metadata, field=\"price\")\n",
        "\n",
        "def build_cuisine_vector(user, metadata):\n",
        "    return build_vector(user, metadata, field=\"cuisines\")\n",
        "\n",
        "def build_tag_vector(user, metadata):\n",
        "    return build_vector(user, metadata, field=\"tags\")\n",
        "\n",
        "def build_location_vector(user, metadata):\n",
        "    return build_vector(user, metadata, field=\"location\")\n",
        "\n",
        "def get_review_embedding(user):\n",
        "    if not user[\"reviews\"]:\n",
        "        return np.zeros(384)\n",
        "    embeddings = model.encode(user[\"reviews\"])\n",
        "    return np.mean(embeddings, axis=0)"
      ],
      "metadata": {
        "id": "XHYG6qW9wcyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taste vectors for mock users\n",
        "userA_vectors = {\n",
        "    \"cuisine_vector\": build_cuisine_vector(userA, restaurant_metadata),\n",
        "    \"tag_vector\": build_tag_vector(userA, restaurant_metadata),\n",
        "    \"price_vector\": build_price_vector(userA, restaurant_metadata),\n",
        "    \"location_vector\": build_location_vector(userA, restaurant_metadata),\n",
        "    \"review_vector\": get_review_embedding(userA)\n",
        "}\n",
        "\n",
        "userB_vectors = {\n",
        "    \"cuisine_vector\": build_cuisine_vector(userB, restaurant_metadata),\n",
        "    \"tag_vector\": build_tag_vector(userB, restaurant_metadata),\n",
        "    \"price_vector\": build_price_vector(userB, restaurant_metadata),\n",
        "    \"location_vector\": build_location_vector(userB, restaurant_metadata),\n",
        "    \"review_vector\": get_review_embedding(userB)\n",
        "}"
      ],
      "metadata": {
        "id": "bx5Mk4VnxF1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compatibility with cosine\n",
        "def dict_cosine(d1, d2):\n",
        "    keys = set(d1.keys()).union(d2.keys())\n",
        "    v1 = np.array([d1.get(k, 0) for k in keys])\n",
        "    v2 = np.array([d2.get(k, 0) for k in keys])\n",
        "    return cosine_similarity([v1], [v2])[0][0]\n",
        "\n",
        "def compute_compatibility(u1, u2):\n",
        "    return round(100 * (\n",
        "        0.3 * dict_cosine(u1[\"cuisine_vector\"], u2[\"cuisine_vector\"]) +\n",
        "        0.2 * dict_cosine(u1[\"tag_vector\"], u2[\"tag_vector\"]) +\n",
        "        0.15 * dict_cosine(u1[\"price_vector\"], u2[\"price_vector\"]) +\n",
        "        0.15 * dict_cosine(u1[\"location_vector\"], u2[\"location_vector\"]) +\n",
        "        0.2 * cosine_similarity([u1[\"review_vector\"]], [u2[\"review_vector\"]])[0][0]\n",
        "    ), 2)"
      ],
      "metadata": {
        "id": "BU5IeZ6IzCg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = compute_compatibility(userA_vectors, userB_vectors)\n",
        "print(f\"ðŸ§  Jaysen and Alex's taste compatibility: {score}%\")"
      ],
      "metadata": {
        "id": "SeqZgtaYzGEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yelp Data"
      ],
      "metadata": {
        "id": "i3sRFwgVIuFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import tarfile"
      ],
      "metadata": {
        "id": "zOds8vWWXIrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WbERtKQ4IwxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extact data\n",
        "import tarfile\n",
        "\n",
        "tar_path = '/content/drive/MyDrive/data/yelp_dataset.tar'\n",
        "extract_path = '/content/drive/MyDrive/data/yelp_data'\n",
        "\n",
        "with tarfile.open(tar_path, 'r') as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "# this didnt get all of the jsons so had to individually extract.."
      ],
      "metadata": {
        "id": "vW1w9aLQI1G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y tar"
      ],
      "metadata": {
        "id": "fW8SafUHOG1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get business data - ONLY NEED TO DO ONCE\n",
        "tar_path = '/content/drive/MyDrive/data/yelp_dataset.tar'\n",
        "output_dir = '/content/drive/MyDrive/data/yelp_data'\n",
        "\n",
        "with tarfile.open(tar_path, 'r') as tar:\n",
        "    members = [m for m in tar.getmembers() if 'yelp_academic_dataset_business.json' in m.name]\n",
        "    tar.extractall(path=output_dir, members=members)\n",
        "\n",
        "print(\"âœ… Extracted business JSON only\")"
      ],
      "metadata": {
        "id": "3mD3PvqpOMLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get review data - ONLY NEED TO DO ONCE\n",
        "with tarfile.open(tar_path, 'r') as tar:\n",
        "    members = [m for m in tar.getmembers() if 'yelp_academic_dataset_review.json' in m.name]\n",
        "    tar.extractall(path=output_dir, members=members)\n",
        "\n",
        "print(\"âœ… Extracted review JSON only\")"
      ],
      "metadata": {
        "id": "Mo5M70JUOtay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering rules\n",
        "# whitelist beli-relevant keywords, blacklist extremely irrelevant keywords\n",
        "csv_path = '/content/drive/MyDrive/data/Updated_Whitelist_and_Blacklist.csv'\n",
        "lists_df = pd.read_csv(csv_path)\n",
        "\n",
        "whitelist = set(lists_df['Whitelist'].dropna().str.lower())\n",
        "blacklist = set(lists_df['Blacklist'].dropna().str.lower())\n",
        "\n",
        "def is_food_related(categories):\n",
        "    if not isinstance(categories, str):\n",
        "        return False\n",
        "    category_list = [cat.strip().lower() for cat in categories.split(',')]\n",
        "    return any(cat in whitelist for cat in category_list)\n",
        "\n",
        "def is_blacklisted(categories):\n",
        "    if not isinstance(categories, str):\n",
        "        return False\n",
        "    category_list = [cat.strip().lower() for cat in categories.split(',')]\n",
        "    return any(cat in blacklist for cat in category_list)"
      ],
      "metadata": {
        "id": "9cbYsAcfJSAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a new json with filtered businesses (beli-relevant)\n",
        "# ONLY NEED TO DO ONCE BC WE STORED NEW JSON\n",
        "\n",
        "# base_dir = '/content/drive/MyDrive/data/yelp_data'\n",
        "# original_file = os.path.join(base_dir, 'yelp_academic_dataset_business.json')\n",
        "# filtered_file = os.path.join(base_dir, 'filtered_businesses.jsonl')\n",
        "\n",
        "\n",
        "# with open(original_file, 'r', encoding='utf-8') as infile, \\\n",
        "#      open(filtered_file, 'w', encoding='utf-8') as outfile:\n",
        "\n",
        "#     for line in infile:\n",
        "#         try:\n",
        "#             business = json.loads(line)\n",
        "#             cats = business.get('categories')\n",
        "#             if is_food_related(cats) and not is_blacklisted(cats):\n",
        "#                 outfile.write(json.dumps(business) + '\\n')\n",
        "#         except json.JSONDecodeError:\n",
        "#             continue\n"
      ],
      "metadata": {
        "id": "aBYS2ZmWKyDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# possibly delete the original file for space\n",
        "# os.remove(original_file)\n",
        "# print(f\"Deleted original file: {original_file}\")"
      ],
      "metadata": {
        "id": "uPWWyJUtLugP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turn filtered business json into df\n",
        "\n",
        "filtered_path = '/content/drive/MyDrive/data/yelp_data/filtered_businesses.jsonl'\n",
        "\n",
        "# Load into DataFrame\n",
        "filtered_businesses_df = pd.read_json(filtered_path, lines=True)\n",
        "\n",
        "# get business ids to use for matching/fitlering other datasets\n",
        "filtered_business_ids = set(filtered_businesses_df['business_id'])\n",
        "\n",
        "print(f\"âœ… Loaded {len(filtered_businesses_df)} businesses\")"
      ],
      "metadata": {
        "id": "QPtYdsWzRXAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter reviews to match businesses\n",
        "# ONLY NEED TO DO ONCE BC WE STORED NEW JSON\n",
        "\n",
        "# review_input_path = '/content/drive/MyDrive/data/yelp_data/yelp_academic_dataset_review.json'\n",
        "# filtered_review_output_path = '/content/drive/MyDrive/data/yelp_data/filtered_reviews.jsonl'\n",
        "\n",
        "# # Stream and filter\n",
        "# with open(review_input_path, 'r', encoding='utf-8') as infile, \\\n",
        "#      open(filtered_review_output_path, 'w', encoding='utf-8') as outfile:\n",
        "\n",
        "#     for line in infile:\n",
        "#         try:\n",
        "#             review = json.loads(line)\n",
        "#             if review['business_id'] in filtered_business_ids:\n",
        "#                 outfile.write(json.dumps(review) + '\\n')\n",
        "#         except json.JSONDecodeError:\n",
        "#             continue\n",
        "\n",
        "# print(\"âœ… Finished filtering reviews\")"
      ],
      "metadata": {
        "id": "BsJF_Z-_Rit6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get user ids from reviews without making a df bc ram is cooked\n",
        "\n",
        "filtered_reviews_path = '/content/drive/MyDrive/data/yelp_data/filtered_reviews.jsonl'\n",
        "relevant_user_ids = set()\n",
        "\n",
        "with open(filtered_reviews_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            review = json.loads(line)\n",
        "            relevant_user_ids.add(review['user_id'])\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "\n",
        "print(f\"âœ… Found {len(relevant_user_ids):,} unique user IDs\")"
      ],
      "metadata": {
        "id": "3vunynXcRpf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter users to match reviews\n",
        "# ONLY DO ONCE\n",
        "\n",
        "# user_json_path = '/content/drive/MyDrive/data/yelp_data/yelp_academic_dataset_user.json'\n",
        "# filtered_users_path = '/content/drive/MyDrive/data/yelp_data/filtered_users.jsonl'\n",
        "\n",
        "# # Filter and write\n",
        "# with open(user_json_path, 'r', encoding='utf-8') as infile, \\\n",
        "#      open(filtered_users_path, 'w', encoding='utf-8') as outfile:\n",
        "\n",
        "#     for line in infile:\n",
        "#         try:\n",
        "#             user = json.loads(line)\n",
        "#             if user['user_id'] in relevant_user_ids:\n",
        "#                 outfile.write(json.dumps(user) + '\\n')\n",
        "#         except json.JSONDecodeError:\n",
        "#             continue\n",
        "\n",
        "# print(f\"âœ… Done! Filtered users saved to: {filtered_users_path}\")"
      ],
      "metadata": {
        "id": "_rNuIEfkVZKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Look at data**"
      ],
      "metadata": {
        "id": "0QMBhvflbSAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_businesses = []\n",
        "\n",
        "with open('/content/drive/MyDrive/data/yelp_data/filtered_businesses.jsonl', 'r', encoding='utf-8') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 10: break\n",
        "        sampled_businesses.append(json.loads(line))\n",
        "\n",
        "# Display\n",
        "import pandas as pd\n",
        "pd.DataFrame(sampled_businesses)"
      ],
      "metadata": {
        "id": "mcEONeqaXECI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_reviews = []\n",
        "\n",
        "with open('/content/drive/MyDrive/data/yelp_data/filtered_reviews.jsonl', 'r', encoding='utf-8') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 10: break\n",
        "        sampled_reviews.append(json.loads(line))\n",
        "\n",
        "pd.DataFrame(sampled_reviews)"
      ],
      "metadata": {
        "id": "icMuPGxHXW48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_users = []\n",
        "\n",
        "with open('/content/drive/MyDrive/data/yelp_data/filtered_users.jsonl', 'r', encoding='utf-8') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 10: break\n",
        "        sampled_users.append(json.loads(line))\n",
        "\n",
        "pd.DataFrame(sampled_users)"
      ],
      "metadata": {
        "id": "8nxHQaKjXXZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change this so that we do all the preprocessing at once !!!!!!\n",
        "\n",
        "input_path = '/content/drive/MyDrive/data/yelp_data/filtered_businesses.jsonl'\n",
        "output_path = '/content/drive/MyDrive/data/filtered_businesses_with_price.jsonl'\n",
        "\n",
        "def extract_price_range(business):\n",
        "    attr = business.get('attributes')\n",
        "    if isinstance(attr, dict):\n",
        "        business['price_range'] = attr.get('RestaurantsPriceRange2')\n",
        "    else:\n",
        "        business['price_range'] = None\n",
        "    return business\n",
        "\n",
        "# Stream and write\n",
        "with open(input_path, 'r', encoding='utf-8') as infile, \\\n",
        "     open(output_path, 'w', encoding='utf-8') as outfile:\n",
        "\n",
        "    for line in infile:\n",
        "        try:\n",
        "            business = json.loads(line)\n",
        "            business = extract_price_range(business)\n",
        "            outfile.write(json.dumps(business) + '\\n')\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "\n",
        "print(\"âœ… Saved businesses with price_range extracted.\")\n"
      ],
      "metadata": {
        "id": "jQsygTCaXdpH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}